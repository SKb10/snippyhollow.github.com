<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: logic | Exchangeable random experiments]]></title>
  <link href="http://snippyhollow.github.com/blog/categories/logic/atom.xml" rel="self"/>
  <link href="http://snippyhollow.github.com/"/>
  <updated>2013-04-19T09:12:37+02:00</updated>
  <id>http://snippyhollow.github.com/</id>
  <author>
    <name><![CDATA[syhw]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[From hacks to Bayesian probability]]></title>
    <link href="http://snippyhollow.github.com/blog/2013/03/08/from-hacks-to-bayesian-probability/"/>
    <updated>2013-03-08T18:58:00+01:00</updated>
    <id>http://snippyhollow.github.com/blog/2013/03/08/from-hacks-to-bayesian-probability</id>
    <content type="html"><![CDATA[<p>In which we look at two pragmatic hacks that lead to the Bayesian approach of probabilities, when pushed further and added as constraints.</p>

<h2 id="coinflips">Coinflips</h2>

<p>Let’s say we have a coin, and we want to decide if it’s fair. We throw it $N$ times and we get $m$ heads, we can code heads=1, tails=0. With $\mu$ the ratio of heads:</p>

<script type="math/tex; mode=display"> 
P(m | N, \mu) = Binomial(m|N,\mu) = \binom{N}{m} \mu^m (1-\mu)^{N-m}
</script>

<h3 id="maximum-likelihood">Maximum likelihood</h3>
<p>How do we set $\mu$? We could maximize the probability of the data that we saw under our model, that is maximizing the <em>likelihood</em>. Let’s say that $D = {x_1 \dots x_N}$, then we have:</p>

<script type="math/tex; mode=display">
P(D|\mu) = \prod_{n=1}^N P(x_n|\mu) = \prod_{n=1}^N \mu^{x_n}(1-\mu)^{1-x_n}
</script>

<p>The maximum of this function of $\mu$ is reached for $\mu= \frac{m}{N}$. The problem arises if we have little data (in fact, when we have data that does not cover the whole space of possible data). If $D=(1,1,1)$, the maximum likelihood estimate of $\mu$ will be $1.0$. It means that we predict that <em>all</em> the tosses will land on heads, after only three observations!</p>

<h3 id="smoothing">Smoothing</h3>

<p>A classical hack is to smooth the maximum likelihood estimate by adding “fake data”, we could consider that we already saw the coin land on heads and tails once, before getting our data. This way, before (“prior to”) the experiment, we would have $\mu=1/2=0.5$. After (<em>posterior</em> to) our experiment, taking the data into account, we would have $\mu = (3+1)/(3+2) = 0.8$. How do we set the these prior coin flips (smoothing parameters)?</p>

<h3 id="maximum-a-posteriori">Maximum A Posteriori</h3>

<p>The <em>right way</em> to encode this prior knowledge is to put a probability distribution on the parameter $\mu$. As $\mu$ is a ratio, we should have a continuous distribution on $[0, 1]$ that can represent a whole range of prior belief on what the coin’s ratio of heads is. For these reasons, a sensible choice is the Beta distribution:</p>

<script type="math/tex; mode=display">
Beta(\mu|a, b) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \mu^{a-1}(1-\mu)^{b-1}
</script>

<p>On Wikpedia, we can check how the $Beta(x|\alpha, \beta)$ distribution looks like:</p>

<p><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Beta_distribution_pdf.svg/639px-Beta_distribution_pdf.svg.png" alt="Plots of the Beta distribution" /></p>

<p>Now we can compute again what is the <em>posterior</em> value of $\mu$ knowing the data $D$ and the prior Beta ($\propto$ means “proportional to”):</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align}
P(\mu | a_0, b_0, D) & \propto P(D|\mu)P(\mu|a_0, b_0)\\
                    & \propto \left( \prod_{n=1}^N \mu^{x_n} (1-\mu)^{1-x_n} \right) Beta(\mu | a_0, b_0)
\end{align}
 %]]&gt;</script>

<p>Hopefully, the Beta distribution is the conjugate prior for the Bernouilli and binomial distributions, and thus a bit of calculus reduces it to:</p>

<script type="math/tex; mode=display">
P(\mu | a_0, b_0, D) \propto Beta(\mu|a_N, b_N)\\
a_N = a_0 + m\\
b_N = b_0 + (N-m)
</script>

<p>We can compute that, when $N \rightarrow \infty$, the expectation of $\mu$: $\mathbb{E}[\mu] = \mu_{ML}$, as:</p>

<script type="math/tex; mode=display">
\mathbb{E} [\mu | a_0, b_0, D] = \frac{a_N}{b_N}
</script>

<h3 id="first-conclusion">First conclusion</h3>

<p>This approach of using a prior on the parameters of the distributions that are essential to our model (the predicting distribution) is central to the Bayesian approach of building models. It makes the model robust to what can happen, even though we had few data. It makes it easier to reason about our prior assumptions that simply “adding unseen data”, and it yields in the presence of more data.</p>

<p>If you’re interested about Bayesian modeling, there are plenty of very good textbooks. My prefered gradual introduction is <a href="http://www.amazon.com/gp/product/0521642981/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0521642981&amp;linkCode=as2&amp;tag=syhwsblog-20">MacKay’s ITILA</a>, that you can find as a <a href="http://www.inference.phy.cam.ac.uk/itila/book.html">free ebook</a>.</p>

<h2 id="causality">Causality</h2>

<p>Now here is another hack for logical reasoning, that leads to Bayesian probabilities. Let’s say that you want to express that an event $A$ entails an event $B$, in logic you would write $A \Rightarrow B$. We will be abusing the notation $A=[A=true]$ and $\neg A=[A=false]$. Now with the <a href="http://en.wikipedia.org/wiki/Modus_ponens"><em>modus ponens</em></a>, you can deduce $B$ whenever $A$ is true.</p>

<script type="math/tex; mode=display">
\frac{[A\Rightarrow B] \wedge A}{B}
</script>

<h3 id="plausible-reasoning">Plausible reasoning</h3>

<p>Now, we want to extend prepositional logic to <em>plausible reasoning</em>, in which we can have degrees of probability that rules are true; or degrees of belief in these rules and facts. A pragmatic way to do that is to introduce the variable $C$ which represents $A \Rightarrow B$, that is: if $P(C)=p$, there is a probability $p$ that $A \Rightarrow B$. Then, this previous <em>modus ponens</em> translates to:</p>

<script type="math/tex; mode=display">
P(B|A,C) = \frac{P(A|B,C)P(B|C)}{P(A|C)}\ (Bayes'\ theorem)\\
P(B|A,C)=\frac{P(A,B|C)}{P(A|C)}\ (Product\ rule)
</script>

<p>And actually, as $P(A,B|C)=P(A|C)$, we have $P(B|A,C)=1$, which corresponds to the strong syllogism of <em>modus ponens</em>. </p>

<p>So now, if we are only 80% sure of $C$, we can write $P(C) = 0.8$ and seek for $P(B|A)$ (we are 100% sure of A):</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align}
P(B|A) = \frac{\sum_{C\in\{false,true\}} P(B|A,C)P(A)P(C)}{P(A)} & = P(\neg C)P(B|A,\neg C) + P(C)P(B|A,C)\\
& = 0.2*x(\in [0,1]) + 0.8*1.0 \geq 0.8
\end{align}
 %]]&gt;</script>

<p>Which means that $B$ has 80% chances to be true by following the strong syllogism of modus ponens, but it can also be true even though $C=false$.</p>

<p>Finally, contrary to prepositional logic, we <em>also</em> get the weak syllogism (and I’ll let you think it through):</p>

<script type="math/tex; mode=display">
\frac{[A\Rightarrow B] \wedge A}{A\ becomes\ more\ plausible}
</script>

<p>A similar derivation and observation can be done for <a href="http://en.wikipedia.org/wiki/Modus_tollens"><em>modus tollens</em></a>.</p>

<h3 id="cox-jaynes-theorem">Cox-Jaynes theorem</h3>

<p>A reasoning mechanism needs to be consistent (one cannot prove $A$ and $\neg A$ at the same time). For plausible reasoning, consistency means: a) all the possible ways to reach a conclusion leads to the same result, b) information cannot be ignored, c) two equal states of knowledge have the same plausibilities. Adding consistency to plausible reasoning leads to <a href="http://en.wikipedia.org/wiki/Cox's_theorem">Cox’s theorem</a>, which derives the laws of probability (the product-rule and the sum-rule). So, the degrees of belief of any consistent induction mechanism verify Kolmogorov’s axioms.</p>

<h3 id="second-and-last-conclusion">Second and last conclusion</h3>

<p>With plausible reasoning, we get all the benefits of prepositional logic, but we can also reason with/about facts and rules that are not 100% true. We have another example of how a pragmatical (sensical) hack to extend logic to “degrees of beliefs” (probabilities) leads to Bayesian probabilities. </p>

<p>If you are interested by learning about plausible reasonning, you can <a href="http://emotion.inrialpes.fr/people/synnaeve/phdthesis/phdthesis.html#x1-590003.2">look at my thesis</a>, or, better yet, read it directly from one of the masters in <a href="http://www.amazon.com/gp/product/0521592712/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0521592712&amp;linkCode=as2&amp;tag=syhwsblog-20">Jayne’s Probability Theory: The Logic of Science</a> for which the pre-print is <a href="http://www-biba.inrialpes.fr/Jaynes/prob.html">there</a>.</p>

]]></content>
  </entry>
  
</feed>
